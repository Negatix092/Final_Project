{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import Sequence\n",
    "from scipy.io import loadmat\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class MatDataGenerator(Sequence):\n",
    "    def __init__(self, mat_files, batch_size, shuffle=True):\n",
    "        self.mat_files = mat_files\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(mat_files))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        # Determine max_length once during initialization\n",
    "        self.max_length = self.determine_max_length()\n",
    "\n",
    "    def determine_max_length(self):\n",
    "        max_length = 0\n",
    "        for file in self.mat_files:\n",
    "            mat_data = loadmat(file, squeeze_me=True, struct_as_record=False)\n",
    "            length = len(mat_data['id'])\n",
    "            if length > max_length:\n",
    "                max_length = length\n",
    "        return max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.mat_files) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get batch of .mat file names\n",
    "        batch_indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        batch_mat_files = [self.mat_files[i] for i in batch_indices]\n",
    "        \n",
    "        # Lists to store batch data\n",
    "        X = [] # inputs\n",
    "        y = [] # outputs\n",
    "\n",
    "        # Loop over each .mat file in the batch\n",
    "        for file in batch_mat_files:\n",
    "            mat_data = loadmat(file, squeeze_me=True, struct_as_record=False)\n",
    "            \n",
    "            # Extract input and output variables and reshape them\n",
    "            inputs = np.hstack([mat_data[var].reshape(-1, 1) for var in ['id', 'id_ref', 'IntErr_Id', 'IntErr_Iq', 'iq', 'iq_ref']])\n",
    "            outputs = np.hstack([mat_data[var].reshape(-1, 1) for var in ['v_md', 'v_mq']])\n",
    "            \n",
    "            # Pad the sequences to self.max_length\n",
    "            inputs = pad_sequences(inputs, maxlen=self.max_length, padding='post')\n",
    "            outputs = pad_sequences(outputs, maxlen=self.max_length, padding='post')\n",
    "            \n",
    "            X.append(inputs)\n",
    "            y.append(outputs)\n",
    "\n",
    "        # Convert lists to numpy arrays\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"D:/Data\"  # Directory containing all .mat files\n",
    "\n",
    "all_mat_files = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.endswith('.mat')]\n",
    "\n",
    "np.random.shuffle(all_mat_files)  # Shuffle the list of .mat files\n",
    "\n",
    "# divide the data into train, test and validation sets\n",
    "# 70% percent of the data is used for training, 15% for testing and 15% for validation\n",
    "\n",
    "num_files = len(all_mat_files)\n",
    "train_files = all_mat_files[:int(0.7 * num_files)] \n",
    "test_files = all_mat_files[int(0.7 * num_files):int(0.85 * num_files)]\n",
    "val_files = all_mat_files[int(0.85 * num_files):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 58.6 TiB for an array with shape (3989800, 4038055) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\valex\\Desktop\\Final_Project\\Test2.ipynb Celda 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/valex/Desktop/Final_Project/Test2.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)  \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/valex/Desktop/Final_Project/Test2.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Training the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/valex/Desktop/Final_Project/Test2.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_gen, validation_data\u001b[39m=\u001b[39;49mval_gen, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\valex\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32mc:\\Users\\valex\\Desktop\\Final_Project\\Test2.ipynb Celda 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/valex/Desktop/Final_Project/Test2.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m outputs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack([mat_data[var]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m var \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mv_md\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mv_mq\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/valex/Desktop/Final_Project/Test2.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Pad the sequences to self.max_length\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/valex/Desktop/Final_Project/Test2.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m inputs \u001b[39m=\u001b[39m pad_sequences(inputs, maxlen\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_length, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/valex/Desktop/Final_Project/Test2.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m outputs \u001b[39m=\u001b[39m pad_sequences(outputs, maxlen\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/valex/Desktop/Final_Project/Test2.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m X\u001b[39m.\u001b[39mappend(inputs)\n",
      "File \u001b[1;32mc:\\Users\\valex\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\numeric.py:344\u001b[0m, in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[0;32m    342\u001b[0m     fill_value \u001b[39m=\u001b[39m asarray(fill_value)\n\u001b[0;32m    343\u001b[0m     dtype \u001b[39m=\u001b[39m fill_value\u001b[39m.\u001b[39mdtype\n\u001b[1;32m--> 344\u001b[0m a \u001b[39m=\u001b[39m empty(shape, dtype, order)\n\u001b[0;32m    345\u001b[0m multiarray\u001b[39m.\u001b[39mcopyto(a, fill_value, casting\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    346\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 58.6 TiB for an array with shape (3989800, 4038055) and data type int32"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Initializing data generators\n",
    "train_gen = MatDataGenerator(train_files, batch_size=32)\n",
    "test_gen = MatDataGenerator(test_files, batch_size=32)\n",
    "val_gen = MatDataGenerator(val_files, batch_size=32)\n",
    "\n",
    "# the model is created \n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_gen.max_length, 6)))\n",
    "model.add(Dense(2))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')  \n",
    "\n",
    "# Training the model\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
